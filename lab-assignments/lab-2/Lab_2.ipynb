{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXgAFwYsgJQnwEDegNHZjD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manika-lamba/SP26-LIS4_5693/blob/main/Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: Text Pre-Processing using spaCy\n",
        "\n",
        "In this lab assignment, we will learn to perform some basic text pre-processing using spaCy.\n",
        "\n",
        "*Note: Before starting this lab assignment, please complete the Introduction to spaCy notebook*\n",
        "\n",
        "## Leaning Objectives\n",
        "\n",
        "In this exercise, you will:\n",
        "\n",
        "- Load and process your own text file (transcript.txt)\n",
        "- Split text into sentences\n",
        "- Count words and sentences\n",
        "- Find frequently used words\n",
        "- Use spaCy’s PhraseMatcher to find specific phrases\n",
        "- Understand the difference between blank pipelines and full pipelines\n",
        "\n",
        "This exercise builds directly on concepts from discussed in the precursor notebook on \"Introduction to spaCy\"."
      ],
      "metadata": {
        "id": "KrmsSk1Yzxjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install spaCy"
      ],
      "metadata": {
        "id": "nn-U5ftJ0ebE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zOaYrB6szuCR",
        "outputId": "887d99df-8c70-4a42-af06-756d63082446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.24.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.3)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (0.24.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.1)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "nf4NfFdQ0vQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and read your file from GitHub\n"
      ],
      "metadata": {
        "id": "e4aSZBw50lIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/manika-lamba/SP26-LIS4_5693/refs/heads/main/lab-2/wiki_us.txt\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status() # Raise an exception for HTTP errors\n",
        "text = response.text"
      ],
      "metadata": {
        "id": "FmwSet870txZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of characters:\", len(text)) # print number of characters\n",
        "\n",
        "print(text[:300])   # print first 300 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5D5nv0Z1Irp",
        "outputId": "3782f278-53cf-4ce0-e9c5-f5d9814f9dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters: 716\n",
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America. It consists of 50 states, a federal district, five major unincorporated territories, nine Minor Outlying Islands, and 326 Indian reservations. It is the t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Segmentation\n",
        "\n",
        "Create a blank spaCy model and add sentencizer."
      ],
      "metadata": {
        "id": "5NkXcTeY2HEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "sentences = list(doc.sents)\n",
        "\n",
        "print(\"Number of sentences:\", len(sentences))\n",
        "\n",
        "print(\"\\nFirst 5 sentences:\")\n",
        "for sent in sentences[:5]:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58uljdmW2OWY",
        "outputId": "a53c460b-eab2-4ce3-a39f-26b67f9631b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 7\n",
            "\n",
            "First 5 sentences:\n",
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "It consists of 50 states, a federal district, five major unincorporated territories, nine Minor Outlying Islands, and 326 Indian reservations.\n",
            "It is the third-largest country by both land and total area.\n",
            "The United States shares land borders with Canada to its north and with Mexico to its south.\n",
            "It has maritime borders with the Bahamas, Cuba, Russia, and other nations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Count and Token Analysis\n",
        "\n",
        "Let's count total words and unique words in your text file."
      ],
      "metadata": {
        "id": "gYBJagaG2XLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [token.text.lower() for token in doc if token.is_alpha]\n",
        "\n",
        "print(\"Total words:\", len(words))\n",
        "print(\"Unique words:\", len(set(words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KuPcIi62dU-",
        "outputId": "44ee14fb-87b6-4f01-869f-4fcb6b4714a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 116\n",
            "Unique words: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Most Frequent Words\n",
        "\n",
        "Let's find top 10 most frequent words in your file."
      ],
      "metadata": {
        "id": "Rl8_kxnb2kIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(words)\n",
        "\n",
        "print(\"Top 10 most frequent words:\")\n",
        "for word, count in word_freq.most_common(10):\n",
        "    print(word, count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCiWP90v2rFZ",
        "outputId": "5af90f55-7c6b-40ce-a58e-dece29e2c67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most frequent words:\n",
            "the 9\n",
            "and 6\n",
            "is 5\n",
            "states 4\n",
            "it 4\n",
            "with 4\n",
            "united 3\n",
            "of 3\n",
            "america 3\n",
            "or 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Full spaCy Pipeline\n",
        "\n",
        "Now use the full model for better linguistic analysis."
      ],
      "metadata": {
        "id": "pwWY7k2q3E19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc2 = nlp2(text)\n",
        "\n",
        "print(\"Named Entities:\")\n",
        "for ent in doc2.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLbCpPFk3KRw",
        "outputId": "c4905b4d-f4fd-401d-8a63-3ec304791827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "The United States of America GPE\n",
            "USA GPE\n",
            "the United States GPE\n",
            "U.S. GPE\n",
            "US GPE\n",
            "America GPE\n",
            "North America LOC\n",
            "50 CARDINAL\n",
            "five CARDINAL\n",
            "nine CARDINAL\n",
            "Minor Outlying Islands ORG\n",
            "326 CARDINAL\n",
            "Indian NORP\n",
            "third ORDINAL\n",
            "The United States GPE\n",
            "Canada GPE\n",
            "Mexico GPE\n",
            "Bahamas GPE\n",
            "Cuba GPE\n",
            "Russia GPE\n",
            "over 331 million MONEY\n",
            "third ORDINAL\n",
            "Washington GPE\n",
            "D.C. GPE\n",
            "New York City GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PhraseMatcher"
      ],
      "metadata": {
        "id": "LYeccjNQ5Xvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "matcher = PhraseMatcher(nlp2.vocab, attr=\"LOWER\")\n",
        "\n",
        "phrases = [\"united states\", \"america\", \"country\"]\n",
        "\n",
        "patterns = [nlp2(p) for p in phrases]\n",
        "\n",
        "matcher.add(\"TECH_TERMS\", patterns)\n",
        "\n",
        "matches = matcher(doc2)\n",
        "\n",
        "print(\"Matches found:\")\n",
        "for match_id, start, end in matches:\n",
        "    print(doc2[start:end])\n",
        "    print(\"Sentence:\", doc2[start].sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJdhOviq5bUn",
        "outputId": "0a64a8a3-f1cf-43e0-eddc-67390cfb8944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches found:\n",
            "United States\n",
            "Sentence: The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "America\n",
            "Sentence: The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "United States\n",
            "Sentence: The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "America\n",
            "Sentence: The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "country\n",
            "Sentence: The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "America\n",
            "Sentence: The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country located in North America.\n",
            "country\n",
            "Sentence: It is the third-largest country by both land and total area.\n",
            "United States\n",
            "Sentence: The United States shares land borders with Canada to its north and with Mexico to its south.\n",
            "country\n",
            "Sentence: With a population of over 331 million, it is the third most populous country in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXCERCISE\n",
        "\n",
        "Open a new Google Colab notebook and complete the tasks below. As you work, add brief explanations using the **Text (Markdown) cells** throughout your notebook to describe what you are doing.\n",
        "\n",
        "1. Make a new folder named `lab-2` in your `lis4693` or `lis5693` repo on GitHub. **[1 Point]**\n",
        "\n",
        "2. Complete the following tasks:\n",
        "\n",
        "\n",
        "**TASK 1**: Load and read your `transcript.txt` file from lab-1 from GitHub repo directly **[1 Point]**\n",
        "\n",
        "**TASK 2**: How many characters are in your transcript? Print the first 100 characters. **[1 Point]**\n",
        "\n",
        "**TASK 3**: Perform sentence segmentation using the blank pipeline\n",
        "  - How many sentences are in your transcript? **[0.5 Point]**\n",
        "  - Print the first 3 sentences **[0.5 Point]**\n",
        "\n",
        "**TASK 4**: Perform Word Count and Token Analysis\n",
        "  - What is the total number of words? **[0.5 Point]**\n",
        "  - What is the number of unique words? **[0.5 Point]**\n",
        "\n",
        "**TASK 5**: Find Most Frequent Words\n",
        "  - What is the most frequent word? **[0.5 Point]**\n",
        "  - Why do you think this word appears frequently? **[1 Point]**\n",
        "\n",
        "**TASK 6**: Run full spaCy pipeline\n",
        "  - How many named entities were found? **[0.5 Point]**\n",
        "  - What types of entities appear? (PERSON, ORG, DATE, etc.) **[0.5 Point]**\n",
        "\n",
        "**TASK 7**: Use PhraseMatcher **[1 Point]**\n",
        "\n",
        "When you selected your YouTube video in Lab-1, what topic or subject were you interested in? Based on that topic, identify three specific phrases that are directly relevant to your search. For example, if your video was about information retrieval, relevant phrases might include \"information retrieval,\" \"text mining,\" and \"data science.\"\n",
        "\n",
        "Make sure the video you selected in Lab-1 was clearly related to your chosen topic and was the same video for which you downloaded the transcript in Lab-1.\n",
        "\n",
        "**TASK 8**: At the end of your Colab notebook, create a new text cell and write a brief reflection for this assignment in a few sentences addressing the following **[2 Points]**:\n",
        " - What went well?\n",
        " - What did not go well or what challenges you encountered?\n",
        "\n",
        "3. Push your Google Colab file to your `lab-2` GitHub repo from Colab. *No points will be given if you upload it to GitHub directly!* **[1 Point]**\n",
        "4. Share the link to your `lab-2` GitHub repo for this lab assignment on CANVAS for credit. **[0.5 Point]**\n"
      ],
      "metadata": {
        "id": "gl10QFLRzuy2"
      }
    }
  ]
}