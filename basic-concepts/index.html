<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Dr.&nbsp;Manika Lamba">
  <title>Text in Context: Basic Concepts</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles.css">
  <link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Text in Context: Basic Concepts</h1>
  <p class="subtitle">LIS 4/5693: Information Retrieval and Text Mining</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr.&nbsp;Manika Lamba 
</div>
</div>
</div>

</section>
<section id="introduction" class="slide level2 smaller">
<h2>Introduction</h2>
<p><strong>Information Retrieval (IR)</strong> is about <code>finding the right documents</code></p>
<p><strong>Natural Language Processing (NLP)</strong> is about <code>understanding language</code></p>
<p><strong>Text Mining</strong> is about <code>discovering patterns and knowledge from large collections of text</code></p>

<img data-src="images/clipboard-3994149887.png" class="quarto-figure quarto-figure-center r-stretch" width="500"><aside class="notes">
<p>Hello everyone! This week’s lecture is divided into two parts. Part 1 focuses on providing you with a brief overview of information retrieval (IR), natural language processing (NLP), and text mining. Part 2 is about how to see the text in context from data ethics specifically data feminism lens.</p>
<p>Before going ahead, I want you to understand how IR, NLP, and text mining are related to each other. Think of these three not as competing fields, but as <strong>layers in a pipeline</strong> and <strong>overlapping research traditions</strong> that work together to extract value from text.</p>
<p>More specifically, <strong>Text analysis/text mining</strong> as an <strong>interdisciplinary field</strong> that sits at the intersection of several established domains. It is not a single technique—it is the <strong>application of computational methods to large collections of text in order to discover patterns, structure, or knowledge</strong> that is not explicitly encoded. To do this, text mining depends heavily on both Information Retrieval and Natural Language Processing.</p>
<p><strong>Information Retrieval</strong> is concerned with <strong>finding relevant documents</strong> in large collections. Classic examples are search engines and digital library systems. IR focuses on questions like: <em>Which documents are relevant to a query? How should documents be indexed? How should relevance be ranked?</em> Importantly, IR usually treats documents as <strong>bags of words</strong>, with limited concern for deep linguistic meaning. In a text mining workflow, IR often comes <strong>first</strong>—it selects the subset of text that will later be analyzed.</p>
<p>On other hand, <strong>Natural Language Processing</strong>, is grounded in <strong>computational linguistics</strong>. NLP is concerned with <strong>understanding and modeling language itself</strong>. This includes tasks such as tokenization, part-of-speech tagging, parsing, named entity recognition, and semantic representation. NLP asks: <em>What does this text mean? What entities, concepts, and relationships are expressed?</em> In text mining, NLP provides the <strong>representations and features</strong> that make deeper analysis possible.</p>
<p>Finally, <strong>text mining</strong> sits at the intersection of IR, NLP, <strong>data mining</strong>, and <strong>machine learning</strong>. While IR finds documents and NLP helps interpret language, text mining focuses on <strong>discovering patterns across many documents</strong>. This includes tasks like <strong>document clustering, document classification, topic modeling, trend detection, and information extraction at scale</strong>. We will cover all these aspects of text mining in detail in this course. Text mining is less about individual texts and more about <strong>collections</strong>, <strong>structure</strong>, and <strong>emergent insights</strong>.</p>
<p>We will also cover machine learning and other recent AI methodologies (including deep learning, LLMs, and Agentic AI) developed in recent years in this course. Machine learning provide the <strong>models and algorithms</strong> that make these tasks scalable and adaptive. Data mining contributes techniques for pattern discovery, while databases and information science contribute methods for managing and organizing large text corpora.</p>
<p>This course will live primarily in that <strong>overlapping center</strong>, showing how IR and NLP are used as tools within broader text mining workflows. Understanding how these fields connect is essential, because real-world text mining systems almost always rely on <strong>all three working together</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="exponential-growth-of-data" class="slide level2 smaller">
<h2>Exponential Growth of Data</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><p>Data and information generation in every discipline in the universe of knowledge has seen staggering growth</p></li>
<li><p>Storing, managing, querying, &amp; retrieval of huge amount of data &amp; information needs sophisticated procedures &amp; advanced technologies</p></li>
<li><p>Nowadays, information collection is web-based and online which is vast and growing at an exponential rate</p></li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/data.png" class="quarto-figure quarto-figure-center" width="700"> <img data-src="images/data.jpg" class="quarto-figure quarto-figure-center" width="700"></p>
</div></div>
<aside class="notes">
<p>The idea of doing data mining or retrieval is driven by one fundamental fact, and that is the digital revolution.The digital revolution happened extremely quickly and profoundly. For example, the figures shown on the slide is taken from <a href="https://www.science.org/doi/10.1126/science.1200970">Hilbert and Lopez (2011)</a> paper which showed that the in the late ’80s, 99% of the information in the world was stored in analogue form, for example on papers. Then, the digital part of information grew but then after the year 2000, it just exploded. They estimated that in the year 2002, for the first time, the world was able to store more digital than analog information. We still have papers around but by now, digital information counts for more than 99% of all the information.</p>
<p>So in the year 2014, when they last updated the data, they found that the world was able to store five zettabytes. How far is five zettabytes? If you would take all this information that you have on your hard disk and your cell phones and microchips on the back of your credit card, and you would put this in books, and you would make a pile, how high do you think the pile would reach? Would reach to the moon? Or to the sun?</p>
<p>It will reach 4,500 times to the sun!! So there will be 4,500 piles from the Earth to the sun with books. So, in 2014, we had 4,500 piles of books. That’s all we were able to accumulate during human history, and now we’re doubling it ever since.</p>
<p>So, we restore as much new information as all the information we were ever able to, there’s a lot of information to dig into and all the time you’re producing a lot more and it’s in digital format. That means then we need a system to compute it and use some system in order to retrieve it.</p>
<p>We live in a time where we’re constantly generating new information and not just a little, but as much as we’ve ever been able to capture. Every day, more knowledge is being produced, and now it’s all in digital form. That’s powerful, because digital information can be stored and preserved almost endlessly.</p>
<p>But here’s the challenge: with so much of it out there, we can’t rely on memory or manual systems anymore. We need computational systems to make sense of it — to process, organize, and connect it. And just as important, we need retrieval systems so that when we ask a question, we can actually pull the right piece of knowledge out of that vast ocean of data.</p>
<p>So, it’s not just about storing information, it’s about creating the ability to use it — instantly, effectively, and intelligently.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="from-data-to-knowledge" class="slide level2 smaller">
<h2>From Data to Knowledge</h2>
<ul>
<li><p>For several years advances in Knowledge Discovery in Databases (KDD) have been undertaken to manage the information in an efficient manner</p></li>
<li><p>Data mining is a part of the KDD process which identifies the hidden patterns in large information repositories</p></li>
<li><p>It involves several information extraction techniques such as regression models, association rules, Bayesian methods, decision trees, neural networks, etc.</p></li>
<li><p>Data can be textual or non-textual in nature</p></li>
<li><p>Textual data are generated from various digital sources such as journals, newspapers, archives, social networks, blogs, forums, etc.</p></li>
</ul>
<aside class="notes">
<p>Knowledge Discovery in Databases, or KDD, which refers to a set of methods developed to manage and make sense of large amounts of information efficiently. As data volumes have grown over the years, KDD has become essential for identifying meaningful information that would be difficult or impossible to find manually.</p>
<p>Data mining is a key step within the KDD process. While KDD describes the overall framework, data mining specifically focuses on discovering hidden patterns, relationships, or trends within large data repositories. In other words, data mining is where insight is actually extracted from data.</p>
<p>To do this, data mining uses a range of information extraction techniques, including regression models, association rules, Bayesian methods, decision trees, and neural networks. Each of these techniques is suited to different types of questions, such as prediction, classification, or pattern detection.</p>
<p>Data can take many forms. It can be textual—such as written language—or non-textual, including images, audio, video, or sensor data. Textual data, in particular, is generated in enormous quantities from digital sources like academic journals, newspapers, archives, social media platforms, blogs, and online forums.</p>
<p>Understanding the variety of data types is important because different forms of data require different mining techniques, and the success of KDD depends on choosing methods that match the nature of the data being analyzed.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval" class="slide level2 smaller">
<h2>Information Retrieval</h2>
<p><code>Definition</code></p>
<blockquote>
<p>A process in which sets of records or documents are searched to find items which may help to satisfy an information need</p>
</blockquote>

<img data-src="images/1.png" class="quarto-figure quarto-figure-center r-stretch" width="344"><div class="footer">
<p><a href="https://doi.org/10.1007/978-3-030-85085-2_1">Lamba and Madhusudhan. (2022). Ch-1 The Computational Library</a></p>
</div>
<aside class="notes">
<p>Now, let’s first begin with understanding Information Retrieval (IR). It is a process of matching a particular document with a set of other relevant documents. Suppose you have an extensive collection of documents and you want to find a relevant document. This text mining task retrieves the relevant documents based on the best matches of input document with the collection of documents based on a similarity measure.</p>
<p>In other words, IR is about bridging the gap between the user’s question and the vast universe of available information.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval-1" class="slide level2 smaller">
<h2>Information Retrieval</h2>
<p>Information Retrieval includes:</p>
<div class="columns">
<div class="column" style="width:50%;">
<ul class="task-list">
<li><p><label><input type="checkbox" checked="">Representation</label></p></li>
<li><p><label><input type="checkbox" checked="">Storage</label></p></li>
<li><p><label><input type="checkbox" checked="">Organization</label></p></li>
<li><p><label><input type="checkbox" checked="">Document Clustering</label></p></li>
<li><p><label><input type="checkbox" checked="">Classification of Documents</label></p></li>
<li><p><label><input type="checkbox" checked="">System Architecture</label></p></li>
</ul>
</div><div class="column" style="width:50%;">
<ul class="task-list">
<li><p><label><input type="checkbox" checked="">Information &amp; Data Visualization</label></p></li>
<li><p><label><input type="checkbox" checked="">Allied Services</label></p></li>
<li><p><label><input type="checkbox" checked="">Ranking of Documents</label></p></li>
<li><p><label><input type="checkbox" checked="">Semantic Linking</label></p></li>
<li><p><label><input type="checkbox" checked="">Filtering</label></p></li>
<li><p><label><input type="checkbox" checked="">Others</label></p></li>
</ul>
</div></div>
<ul>
<li><span style="color: blue;">Search engines</span> have been developed based on the concepts, principles, and techniques developed by IR</li>
</ul>
<aside class="notes">
<p>Now, what does that actually involve? As you see on this slide, IR is not just about search in the narrow sense. It encompasses several key components:</p>
<p>On the left side, we have the foundational activities —– things like representation, which is how we describe documents; storage and organization, which ensure information can be managed at scale; and techniques such as document clustering and classification, which group or categorize information meaningfully. And of course, all of this requires careful consideration of system architecture, the technical backbone of IR.</p>
<p>On the right side, we move into more advanced or applied aspects –— information and data visualization, which helps users interpret results; allied services, which extend retrieval into related tasks; ranking of documents, which determines which results appear most relevant; semantic linking, which connects related pieces of knowledge; and filtering, which helps reduce noise and personalize outputs. These ensure that IR is not just functional, but also efficient and user-centered.</p>
<p>Finally, it’s worth emphasizing that search engines, which we all use daily, are the most visible application of these IR principles. The concepts and techniques you see here form the foundation of systems like Google, Bing, and countless specialized retrieval platforms.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="brief-history-of-information-retrieval" class="slide level2">
<h2>Brief History of Information Retrieval</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>System for the Mechanical Analysis and Retrieval of Text (SMART) was developed by Gerard Salton in Cornell University in 1960s. This system incorporated many important concepts like <span style="color: blue;">vector space model</span>, relevance feedback, and Rocchio Classification</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-1563999917.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<aside class="notes">
<p>The SMART system, or System for the Mechanical Analysis and Retrieval of Text, was one of the earliest and most influential projects in Information Retrieval. It was developed in the 1960s at Cornell University by Gerard Salton, who is often considered the father of IR.</p>
<p>What made SMART so important is that it wasn’t just a system, it was a research platform. It introduced and tested many of the core ideas that modern search engines still rely on. For example, SMART gave us the <strong>vector space model</strong>, representing documents and queries mathematically so that we could measure similarity. It also introduced <strong>term weighting methods</strong> like TF-IDF, which balance how frequent a word is within a document against how rare it is across the collection.</p>
<p>Another innovation was <strong>relevance feedback</strong>, the idea that the system can improve results by learning from what the user marks as relevant or irrelevant. And just as importantly, it also developed <strong>evaluation methods</strong>, such as precision and recall, to measure retrieval effectiveness in a systematic way.</p>
<p>While the SMART system itself no longer exists, its principles form the foundation of everything from academic IR research to commercial search engines like Google today.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="brief-history-of-information-retrieval-1" class="slide level2">
<h2>Brief History of Information Retrieval</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><p>J.W. Sammon (1969) gave the idea of <span style="color: blue;">visualization interface integrated to an IR system</span> in his famous paper “A nonlinear mapping for data structure analysis”</p></li>
<li><p><span style="color: blue;">First online systems</span>–NLM’s AIM-TWX, MEDLINE; Lockheed’s Dialog; SDC’s ORBIT</p></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-1874551088.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
<ul>
<li>During 1966-67, F.W. Lancaster evaluated the <span style="color: blue;">MEDLARS (Medical Literature Analysis and Retrieval System)</span></li>
</ul>
</div></div>
<aside class="notes">
<p>In the late 1960s, researchers began thinking about how information retrieval systems could move beyond simple text search. One key idea came from J.W. Sammon in 1969, who proposed a visualization interface integrated into IR systems. In his influential paper, A Nonlinear Mapping for Data Structure Analysis, he laid the groundwork for techniques that help us see patterns in data, something that’s become critical in modern IR with clustering and visualization tools.</p>
<p>Around the same time, the first online IR systems were emerging. Examples include the National Library of Medicine’s AIM-TWX and MEDLINE, Lockheed’s Dialog, and SDC’s ORBIT. These systems were groundbreaking because they provided searchable access to specialized literature, especially in science and medicine, long before the web existed.</p>
<p>And during 1966–67, F.W. Lancaster conducted a major evaluation of MEDLARS, the Medical Literature Analysis and Retrieval System. His studies were among the first systematic evaluations of an IR system, focusing on how effective it was in retrieving relevant documents. This was crucial, because it marked the beginning of formal evaluation practices in IR, something that still defines the field today.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="brief-history-of-information-retrieval-2" class="slide level2">
<h2>Brief History of Information Retrieval</h2>
<ul>
<li><p><span style="color: blue;">AM SIGIR Conference</span> started in 1978 which subsequently emerged as the apex conference in IR systems</p></li>
<li><p>Belkin, Oddy, and Brooks gave the concept of <a href="https://doi.org/10.1108/eb026722"><em>Anomalous State of Knowledge (ASK)</em></a> for information retrieval in 1982</p></li>
<li><p><span style="color: blue;">OKAPI model</span> was formulated in 1982-88 which is a set-oriented ranked output design for probabilistic type retrieval of textual material using inverted index</p></li>
<li><p>Major breakthrough was in 1989 when Tim Berners-Lee proposed <span style="color: blue;">World Wide Web</span> in CERN Laboratory</p></li>
<li><p><span style="color: blue;">TREC conference</span> started as part of TIPSTER text program in 1992 and it was sponsored by US Defense and National Institute of Standards and Technology (NIST)</p></li>
</ul>
<aside class="notes">
<p>Next in 1978, the ACM SIGIR Conference began. Over time, it became the leading international conference on IR systems, what we often call the ‘apex’ conference in the IR field.</p>
<p>Then, in 1982, Belkin, Oddy, and Brooks introduced the concept of the Anomalous State of Knowledge, or ASK. This was a very important theoretical model because it framed retrieval as a process of resolving a gap in the user’s knowledge, not just matching keywords.</p>
<p>Around the same period, from 1982 to 1988, the OKAPI model was developed. This was a probabilistic retrieval model that produced ranked outputs based on an inverted index. It laid the groundwork for what later became BM25, still one of the most widely used ranking functions today.</p>
<p>A major turning point came in 1989, when Tim Berners-Lee, working at CERN, proposed the World Wide Web. This changed the context of IR completely, shifting from specialized databases to a global, open information space.</p>
<p>In 1992, the TREC conference was launched as part of the TIPSTER text program, sponsored by the U.S. Department of Defense and NIST. TREC provided standardized test collections and evaluation frameworks, which accelerated research and allowed fair comparisons between different retrieval methods.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="brief-history-of-information-retrieval-3" class="slide level2 smaller">
<h2>Brief History of Information Retrieval</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><p><span style="color: blue;">PageRank algorithm</span> was developed at Stanford University by Larry Page and Sergey Brin in 1996</p></li>
<li><p>In 1997, <span style="color: blue;">Google Inc.</span> was born which has now ruling dominantly in searching engine domain</p></li>
<li><p>Google personalized search started in 2005</p></li>
<li><p>Multimedia IR (Smeulders, Lew, Sebe) integrates into search in 2010</p></li>
<li><p>Semantic models came first in 2013-2014 such as Word2Vec, GloVe</p></li>
<li><p>Google introduces BERT in 2018</p></li>
<li><p>Conversational IR in assistants were introduced in 2020-2021 such as Alexa, Siri</p></li>
<li><p>Retrieval Augmented Genreration in 2022-2023</p></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-2203373772.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
<ul>
<li><p>LSI gained huge popularity in WWW and was hugely used in Search Engine Optimization (SEO)</p></li>
<li><p><span style="color: blue;">Latent Dirichlet allocation (LDA)</span>, a generative/topic model in NLP was developed by David Blei, Andrew NG, and Michael Jordan in 2003</p></li>
</ul>
</div></div>
<aside class="notes">
<p>Several key developments mark the evolution of modern information retrieval systems. Some of the selected ones are as follows:</p>
<p>In 1996, at Stanford University, Larry Page and Sergey Brin developed the PageRank algorithm, a seminal contribution that ranked web pages based on link structure rather than just keyword frequency. This innovation became the foundation of Google’s search engine and transformed large-scale web retrieval.</p>
<p>Latent Semantic Indexing, or LSI, gained significant popularity with the growth of the World Wide Web. The method, originally introduced in the late 1980s, was designed to capture hidden semantic structures in text by reducing dimensionality through singular value decomposition. In the context of the web, LSI was quickly adopted in Search Engine Optimization (SEO) practices. The reasoning was that by modeling the semantic relationships among terms, web pages could be optimized not only for exact keywords, but also for related concepts and variations. This marked an early move from simple keyword matching toward a more semantically aware retrieval process.</p>
<p>Although later models like probabilistic topic models and neural embeddings surpassed LSI in accuracy and scalability, its role was historically important – it bridged the gap between traditional keyword-based retrieval and more advanced semantic methods.</p>
<p>In 2003, David Blei, Andrew Ng, and Michael Jordan introduced Latent Dirichlet Allocation (LDA), a probabilistic generative model that enabled documents to be represented as mixtures of latent topics. LDA marked an important theoretical and practical advance in modeling text corpora and topic-driven retrieval.</p>
<p>By 2005, Google introduced personalized search, adapting retrieval results to individual user histories and profiles. This was a shift from universal rankings toward user-centered retrieval models.</p>
<p>In 2010, the field saw the integration of multimedia information retrieval, with researchers such as Smeulders, Lew, and Sebe working on retrieval methods for images, video, and audio. This expanded the scope of IR beyond text into multimodal domains.</p>
<p>The years 2013–2014 introduced the first widely adopted semantic models, particularly Word2Vec (Mikolov et al.) and GloVe (Pennington, Socher, Manning). These embedding models captured semantic relationships in continuous vector spaces and significantly improved retrieval quality.</p>
<p>In 2018, Google introduced BERT (Devlin, Chang, Lee, Toutanova), a deep contextual language model that revolutionized semantic search and natural language understanding within IR systems.</p>
<p>By 2020–2021, conversational IR emerged in mainstream use, integrated into voice assistants such as Alexa, Siri, and Google Assistant, enabling multi-turn, interactive retrieval.</p>
<p>Most recently, in 2022–2023, the rise of Retrieval-Augmented Generation (RAG) has combined neural retrieval with large language models, enabling systems not only to retrieve relevant documents but also to generate coherent, contextually enriched answers. This represents the convergence of IR with generative AI, defining the current frontier of the field.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="who-are-the-users" class="slide level2">
<h2>Who are the Users?</h2>
<blockquote>
<p>A user is a person who uses information and/or information systems in some meaningful way</p>
</blockquote>
<p>A user can be:</p>
<ul>
<li>End-user: seeks, evaluates, uses information for personal question or problem</li>
<li>System-user: end user who exploits information systems at some level</li>
<li>Information professional: facilitates end-user information seeking and use</li>
<li>Computerized system, software program</li>
</ul>
<aside class="notes">
<p>Everyone is an information user and exploits information systems at some level. The literature uses many terms to describe users, such as end users, system users, and information professionals. They are all users of IR systems, right? End users and system users are basically the same. The term end user comes from a time in libraries when users could not access the library catalog and the librarian conducted the searching for them in a closed stack environment. When libraries became automated in the 1970s and 80s the term system users began being used to describe both the end users but also the information professionals who now had access to online resources using dumb terminals (not connected to an external server) and to a small set of subject specific databases.</p>
<p>Computerized systems like bots on the web are also users of our systems, right? The bots access our OPACs to index our collections and make them accessible through search engines.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="users-information-needs" class="slide level2">
<h2>User’s Information Needs</h2>
<p>Users are motivated to seek information in a given situation to:</p>
<ul>
<li>answer a question</li>
<li>solve a problem</li>
<li>complete a task</li>
<li>learn about a subject</li>
<li>verify a fact</li>
<li>just for fun</li>
</ul>
<aside class="notes">
<p>Whether you are a system designer, reference librarian, or just want to become a better searcher, it is important to understand more about WHY and HOW people search for information. Information scientists have long studied what is called Information Behavior (how people find and use information to various purposes) and a subset of information behavior called information seeking, which focuses on the process, tools, and decisions associated with seeking for information.</p>
<p>Generally we know that users are motivated to seek information as part of a situational context to answer a question, solve a problem, complete a task, to learn more or verify a fact. What we know less about is how they seek information for fun or entertainment. There are some very interesting studies about information seeking for hobbyists, within social media, or just to surf for fun. But we need to learn more.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="users-information-needs-1" class="slide level2">
<h2>User’s Information Needs</h2>
<p>Typical user questions:</p>
<ul>
<li>What</li>
<li>When</li>
<li>Where</li>
<li>Why</li>
<li>How</li>
</ul>
<aside class="notes">
<p>When helping users search or use different IR systems we can expect specific kinds of questions, such as WHAT, WHEN, WHERE, WHY and HOW. Drawing out a user’s actual information need, however, is often challenging as they may not know how to ask the question, how to enter a query into the system, or to use the functions of the system to find what they are looking for.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-needs" class="slide level2">
<h2>Information Needs</h2>
<p>Two broad categories of searches:</p>
<ul>
<li>Known item search</li>
<li>Subject or topic search</li>
</ul>
<aside class="notes">
<p>Research has also shown that there are two broad categories of searches that users conduct:</p>
<ol type="1">
<li><p>Known item searches – where the user knows something about the item they are seeking such as title or author</p></li>
<li><p>Subject or topic searches – the user knows some aspect of the subject or topic that they need to learn more about or that they need to find specific information about.</p></li>
</ol>
<p>This is not quite as simple as it sounds. Very often a user will not know how to express their precise information need or how to implement it within a given system. In modern systems depending on the IR technique of the system or its capabilities to match partial search information, the user can still find useful information.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval-systems" class="slide level2 smaller">
<h2>Information Retrieval Systems</h2>
<blockquote>
<p>A specialized system for the description, storage, and retrieval of information representations: primarily information objects (text, images) and their surrogates (metadata, records). Operates by matching queries (representations of information need) with data (representations of information objects)</p>
</blockquote>

<img data-src="images/clipboard-1371401673.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>This slide briefly explains the IR process and systems. IR systems are specialized systems that are used for the description, storage and retrieval of information representations (or the information objects). These objects can take many forms.</p>
<p>Users access the records of the objects or the objects by matching search terms or queries to data or representations about the objects within the system. IR systems are set up to use algorithms that provide the “matching” function. Older systems primarily were exact match systems, meaning that the query terms and terms in the representation and/or inverted index had to match exactly.</p>
<p>The most significant change in IR systems is that MOST are no longer exact match systems but will match on part of the query terms. Artificial intelligence (AI) and machine learning are also changing expectations of users and how they think search engines and databases to work.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="components-of-ir-systems" class="slide level2">
<h2>Components of IR systems</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Knowledge system into which an IR system is implanted generally consists of three main components:</p>
<ol type="a">
<li><p><span style="color: blue;">people in their role as information-processors</span></p></li>
<li><p><span style="color: blue;">documents in their role as carriers of information</span></p></li>
<li><p><span style="color: blue;">topics as representations</span></p></li>
</ol>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/2.png" class="quarto-figure quarto-figure-center" width="500"></p>
</figure>
</div>
</div></div>
<aside class="notes">
<p>Let us now consider the basic conceptual framework of information retrieval systems.</p>
<p>An IR system is not an isolated tool, but rather one that is implanted within a broader knowledge system.</p>
<p>This system can be thought of as consisting of three interrelated components:</p>
<ol type="1">
<li><p>People, in their role as information processors and seekers of knowledge.</p></li>
<li><p>Documents, in their role as carriers and representations of information.</p></li>
<li><p>Topics, which function as abstract representations of knowledge domains and link users to the documents they seek.</p></li>
</ol>
<p>This slide illustrates a “basic” model of how IR works. On the left side are the documents and representations that are stored by the system. On the right side are the user interactions with the system. The center section shows the matching function and the output or results of the search. Of course in a computer there is much more to it, but this gives us the basic idea of how IR works.</p>
<p>As Lancaster observed, the purpose of an IR system is not to directly inform the user on the subject of their inquiry. Instead, its role is more precise: to inform the user of the existence, non-existence, and whereabouts of documents relevant to their request. In its early conception, therefore, IR was fundamentally about retrieval of documents, not retrieval of information.</p>
<p>This notion shifted significantly with the advent of full-text availability in bibliographic databases. No longer constrained to indexes and metadata, IR systems could now operate directly on the content of documents. Originally, IR meant text retrieval systems, reflecting the textual nature of the collections.</p>
<p>However, modern IR systems increasingly handle multimedia information — not only text, but also images, audio, and video. This transition has required the development of new tools, methods, and techniques capable of supporting retrieval across multiple modalities. It represents one of the major conceptual and technological expansions in the field.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="model-of-ir-system" class="slide level2">
<h2>Model of IR System</h2>

<img data-src="images/3.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>The figure on this slide provides a much more complete picture, expanding each of the functions of the Blair model on the last slide. The actors of each side are also included, such as on the left side, they include content creators, producers of the documents but also the catalogers who provide the descriptions or the metadata associated with each object.</p>
<p>This slide also shows a range of types of documents that might be accessible in a system. This figure also shows the outcomes of the representation process, by the human indexer as well as the computer processing the representations or documents, as well as the standards and tools that are used in the representation process.</p>
<p>In the middle is the search interface and IR technique that provide the matching function. On the right are the users within a societal context, which affects what they know and what types of knowledge they bring when they use an IR system.</p>
<p>At the bottom of this model are other factors, such as national, technological, etc. that affect the context in which an IR system exists. This is one of my favorite models for understanding the complexity of an IR system because it incorporates contextual factors into the model which have direct influence on the IR system and how it is used.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="types-of-ir-systems" class="slide level2 smaller">
<h2>Types of IR Systems</h2>
<p>Based on the different types of services, IR can be categorized as:</p>
<div class="columns">
<div class="column" style="width:50%;">
<ul class="task-list">
<li><p><label><input type="checkbox" checked="">Pre-Coordinate Systems</label></p>
<ul>
<li>Printed indexes and catalogs</li>
<li>OPACs</li>
</ul></li>
<li><p><label><input type="checkbox" checked="">Post-Coordinate Systems</label></p></li>
<li><p><label><input type="checkbox" checked="">Web Search</label></p></li>
<li><p><label><input type="checkbox" checked="">Personalized IR</label></p></li>
<li><p><label><input type="checkbox" checked="">Enterprise/Institutional IR</label></p></li>
<li><p><label><input type="checkbox" checked="">Domain-Specific IR</label></p></li>
</ul>
</div><div class="column" style="width:50%;">
<ul class="task-list">
<li><p><label><input type="checkbox" checked="">Web Based IR System</label></p></li>
<li><p><label><input type="checkbox" checked="">Digital Libraries</label></p></li>
<li><p><label><input type="checkbox" checked="">Multimedia IR System</label></p></li>
<li><p><label><input type="checkbox" checked="">Distributed IR System</label></p></li>
<li><p><label><input type="checkbox" checked="">Conversational IR System</label></p>
<ul>
<li>ChatGPT</li>
</ul></li>
</ul>
</div></div>
<aside class="notes">
<p>Now that we’ve looked at the definition and scope of Information Retrieval, let’s consider the different categories of services that IR supports.</p>
<p>On the left, we see types that focus on <strong>context and users</strong>:</p>
<p><strong>Web Search</strong>, the most familiar to all of us, where IR powers large-scale search engines across the open internet.</p>
<p><strong>Personalized IR</strong>, which adapts results to individual user preferences and past behaviors.</p>
<p><strong>Enterprise or Institutional IR</strong>, which focuses on retrieving information within organizations — for example, searching across company documents or academic repositories.</p>
<p>And <strong>Domain-Specific IR</strong>, which is specialized for a particular field such as medicine, law, or engineering, where terminology and relevance criteria are unique.</p>
<p>On the right, we have <strong>system-based services</strong>:</p>
<p><strong>Web-Based IR Systems</strong>, which deliver retrieval through online interfaces.</p>
<p><strong>Digital Libraries</strong>, which apply IR to structured, curated collections of academic and cultural material.</p>
<p><strong>Multimedia IR Systems</strong>, which extend beyond text to include images, audio, and video retrieval.</p>
<p>And finally, <strong>Distributed IR Systems</strong>, which work across multiple, separate data sources — for example, federated search across libraries, or even across multiple company systems.</p>
<p>The important takeaway here is that IR isn’t one-size-fits-all. Different contexts whether public web search, personalized recommendation, or specialized domains, demand different architectures and retrieval strategies.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-information-can-you-find-online" class="slide level2">
<h2>What Information Can You Find Online?</h2>
<ul>
<li>Bibliographic citations</li>
<li>Full-text documents</li>
<li>Directory of reference sources</li>
<li>Numeric data</li>
<li>Images</li>
<li>Multimedia files</li>
</ul>
<aside class="notes">
<p>Not to be flippant, but did you laugh the first time you heard someone say that you can find everything online?</p>
<p>It is very common misconception of users that they can access everything online. While the availability of content and what you can find online has definitely improved, not everything can be found online.</p>
<p>What is also key to remember is that you need to know which systems hold specific types of information, so you choose an appropriate system.</p>
<p>For example, if you are looking for a book to purchase you might use the Web and Amazon or Barnes and Noble. If you just want to borrow a book you would search for it in the library catalog and may find it easily accessible or the library may have to order it for you.</p>
<p>To locate scholarly articles, like those usually required for research papers in your classes, you would use OU Libraries subject/discipline specific databases.</p>
<p>You can, in some instances, use Google Scholar, but often you end up with a citation that requires payment to access the actual article. AND Google Scholar is not as heavily indexed so you may miss relevant articles if you use different terms than what is in the Google Scholar index.</p>
<p>The point here is that choosing the correct system is critical in finding the useful data you need. We will talk about this more in our next lecture on “Acquiring Text”.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="natural-language-processing-nlp" class="slide level2">
<h2>Natural Language Processing (NLP)</h2>
<ul>
<li>Free text searching = flexiblity + complexity</li>
<li>NLP is essential for modern IR</li>
<li>Conversational interfaces are shaping the future in library search</li>
</ul>
<aside class="notes">
<p>Now, let’s discuss natural language search and its role in modern information retrieval.</p>
<p>First, we will discuss how free text searching represents both an opportunity and a challenge. Its flexibility allows users to articulate queries in their own words, fostering inclusivity and accessibility. Yet this same flexibility introduces complexity, requiring sophisticated processing to manage linguistic ambiguity, synonymy, and varying query structures. The effectiveness of free text search therefore depends on the strength of the underlying linguistic and computational models.</p>
<p>Second, we will see how Natural Language Processing or NLP has become indispensable for contemporary information retrieval. From tokenization and indexing to intent detection and semantic modeling, NLP techniques enable systems to move beyond surface-level keyword matching toward genuine understanding of user queries and document meaning. NLP thus serves as the foundation upon which intelligent, adaptive, and context-aware retrieval systems are built.</p>
<p>Finally, we will discuss how conversational interfaces—including voice-based assistants and chatbots—are reshaping the landscape of library search and discovery. By facilitating dialogue-like interactions, these systems make information retrieval more natural, accessible, and responsive. They extend the mission of libraries by offering scalable, human-centered engagement, and they signal the ongoing convergence of librarianship, computational linguistics, and artificial intelligence.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="document-indexing-and-retrieval" class="slide level2">
<h2>Document Indexing and Retrieval</h2>
<ul>
<li>Methods include
<ul>
<li>Boolean</li>
<li>Vector Space</li>
<li>Probabilistic</li>
</ul></li>
<li>Rely on <em>index terms</em>
<ul>
<li><em>“bag of words”</em></li>
<li>stoplist + stemming</li>
</ul></li>
<li>But text is “unstructured”
<ul>
<li>information may be “hidden”</li>
</ul></li>
</ul>
<aside class="notes">
<p>We have three core <strong>document retrieval strategies</strong>: (i) <strong>Boolean</strong>, (ii) <strong>Vector Space</strong>, and (iii) <strong>Probabilistic</strong> models.</p>
<p>All of these models depend on <strong>index terms</strong>, which are the keywords or tokens that represent the main ideas in a document. This is often referred to as the <strong>“bag of words”</strong> approach where the information system treats each document as an unordered collection of words, ignoring sentence structure or grammar. To make this more efficient, we use <strong>stoplists</strong> to filter out common, low-value words (like “the,” “is,” or “and”) and <strong>stemming</strong> to reduce words to their root forms, such as turning “learning,” “learns,” and “learned” into “learn.”</p>
<p>However, the limitation here is that <strong>text is unstructured</strong>. It doesn’t follow a fixed schema like a database, that is, meaning, context, and relationships between words are often <strong>hidden</strong>. A keyword match might miss the nuance of how terms are actually used.</p>
<p>This challenge led to the evolution toward <strong>free-text</strong> and <strong>natural language searching</strong>. Instead of relying only on index terms or Boolean logic, these approaches allow users to search using <strong>everyday language</strong>, such as typing “What are the best ways to learn machine learning?” rather than just “machine learning AND tutorial.”</p>
<p>Here’s where Natural Language Processing comes in —- it builds on these traditional retrieval models by helping computers interpret meaning, context, and intent behind a query. NLP-enhanced search systems can understand synonyms, recognize entities, and analyze sentiment — turning unstructured text into structured, meaningful data that can be retrieved intelligently.</p>
<p>So, in essence, Boolean, vector, and probabilistic models gave us the foundation for <strong>structured retrieval</strong>, while NLP and semantic understanding expanded that foundation into <strong>natural, conversational searching</strong> — the kind of search experience we now expect on platforms like Google, YouTube, and social media.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problems-with-text" class="slide level2 smaller">
<h2>Problems with Text</h2>
<ul>
<li><code>Polysemy</code>: one word maps to many concept such as bat</li>
<li><code>Synonymy</code>: one concept maps to many words such as happy or joyful, car or automobile</li>
<li><code>Word order</code></li>
<li><code>Language is generative</code>
<ul>
<li><p><em>Starbucks coffee is the best</em></p></li>
<li><p><em>The place I like most when I need to feed my caffeine addiction is the company from Seattle with branches everywhere</em></p></li>
</ul></li>
<li><code>Many different ways to express given idea</code>
<ul>
<li>synonymy, paraphrase, metaphor, etc</li>
</ul></li>
<li><code>Frege's principle</code>: <em>The meaning of a sentence is completely determined by the meaning of its symbols and the syntax used to combine them</em></li>
</ul>
<aside class="notes">
<p>When we work with text data, one of the biggest challenges is that <strong>human language isn’t straightforward</strong>. There are many ways to say the same thing, and words often mean different things depending on context — which makes text processing far more complex than working with structured data like numbers or categories.</p>
<p>Let’s look at a few of the main <strong>problems with text</strong>.</p>
<p>First, there’s <strong>polysemy</strong>, which means a single word can have <strong>multiple meanings</strong>. For example, the word <em>“bat”</em> can refer to an animal or a piece of sports equipment. Humans can easily infer which meaning is intended from context, but a computer can’t do that without additional processing or training.</p>
<p>Next, we have <strong>synonymy</strong>, which is the opposite issue -— one concept can be expressed using <strong>many different words</strong>. For example, <em>“happy”</em> and <em>“joyful”</em>, or <em>“car”</em> and <em>“automobile”</em>, all convey the same idea. For a computer that relies on exact word matching, these differences can cause it to miss relevant information.</p>
<p>Then there’s <strong>word order</strong>. In English and many other languages, the order of words changes meaning. For example, <em>“The cat chased the dog”</em> versus <em>“The dog chased the cat”</em> -— same words, completely different meaning. So, computers need to understand syntax and structure, not just individual words.</p>
<p>Another key feature of language is that it’s <strong>generative</strong> —- we can express the same thought in countless ways. For instance, consider the simple statement: <em>“Starbucks coffee is the best.”</em> You could also say, <em>“The place I like most when I need to feed my caffeine addiction is the company from Seattle with branches everywhere.”</em> Both sentences communicate the same core idea, but with very different wording, tone, and structure.</p>
<p>This flexibility through <strong>synonymy, paraphrase, metaphor, and other linguistic devices</strong> is what makes human communication rich and creative, but also what makes text so challenging for machines to process.</p>
<p>Finally, <strong>Frege’s Principle</strong> helps explain why meaning in language can be complex. It states that <em>the meaning of a sentence is completely determined by the meaning of its symbols and the syntax used to combine them.</em> In theory, this means if we understand each word and how they fit together, we should understand the sentence. In practice, though, human language often violates this principle through context, idioms, and implied meaning which is exactly why Natural Language Processing is so essential for text understanding and information retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problems-with-text-cont." class="slide level2 smaller">
<h2>Problems with Text (Cont.)</h2>
<ul>
<li><code>Language is a form of communication</code>
<ul>
<li>All communication has a *context*
<ul>
<li><strong><em>time</em></strong> and <strong><em>place</em></strong> of utterance, the writer, the reader, their <strong>background knowledge</strong>, <strong>intentions</strong>, <strong>assumptions</strong> and the reader’s knowledge/intentions, etc.</li>
</ul></li>
</ul></li>
<li><code>Language is changing</code></li>
<li><code>Ill-formed input</code></li>
<li><code>Co-ordination, negation, etc</code></li>
<li><code>Multi-linguity</code></li>
<li><code>Sarcasm, irony, slang, jargon, etc</code></li>
</ul>
<aside class="notes">
<p>Continuing our discussion on the <strong>problems with text</strong>, we now move beyond just word meaning and structure to look at some deeper challenges that come from the nature of <strong>language as communication</strong>.</p>
<p>First and foremost, <strong>language is a form of communication</strong>, and all communication happens within a <strong>context</strong>. This means that understanding language requires knowing the <strong>time and place</strong> of the utterance, who the <strong>writer or speaker</strong> is, who the <strong>reader or listener</strong> is, and what <strong>background knowledge</strong>, <strong>intentions</strong>, and <strong>assumptions</strong> each person brings. For example, a tweet made during a political event or a comment on a breaking news story may carry meaning that’s only clear when you know when and where it was posted. Without context, computers can easily misinterpret meaning.</p>
<p>Second, <strong>language is constantly changing</strong>. New words, slang, and expressions emerge all the time, especially online. Think about how quickly terms like “ghosting,” “FOMO,” or “AI” entered common use. NLP systems must continually adapt to stay current with these shifts in language and culture.</p>
<p>Next, we have <strong>ill-formed input</strong>, which refers to the fact that people often type or speak in ways that are incomplete, ungrammatical, or filled with typos, abbreviations, and emojis. On social media especially, posts rarely follow perfect grammar rules, so NLP models need to handle noisy, messy data.</p>
<p>Another issue is <strong>coordination and negation</strong>, things like <em>“Mary got home late, and she missed her dinner”</em> or <em>“I don’t dislike this movie.”</em> These constructions can be tricky because meaning changes depending on how clauses are linked or negated. Understanding such nuances requires more than simple word-level analysis.</p>
<p>Then there’s <strong>multilinguality</strong>, or the use of multiple languages. Many users mix languages, for example, switching between English and Spanish in the same sentence. This poses a major challenge for NLP systems that rely on monolingual training data.</p>
<p>Finally, <strong>sarcasm, irony, slang, and jargon</strong> are particularly difficult for computers to interpret. When someone says, <em>“Oh great, another meeting,”</em> they might mean the opposite of what the words literally say. Humans detect tone and social cues naturally, but for machines, this kind of subtlety often leads to misunderstanding.</p>
<p>So, these challenges highlight why <strong>language understanding is far more than pattern matching</strong> – it requires grasping context, culture, tone, and evolution. And that’s exactly why NLP research continues to evolve -— to make computers better at interpreting human communication in all its complexity.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="enter-nlptext-analytics" class="slide level2">
<h2>Enter NLP/Text Analytics</h2>
<ul>
<li><p><code>Text Analytics</code>: a set of <strong>linguistic, analytical</strong>, and <strong>predictive</strong> technique to extract <strong>structure</strong> and <strong>meaning</strong> from unstructured documents</p></li>
<li><p><code>NLP</code>: academic term for Text Analytics</p>
<ul>
<li>analogous to “search” vs.&nbsp;“IR”</li>
<li>Text Analytics ≈ NLP ≈ Text Mining</li>
</ul></li>
</ul>

<img data-src="images/2.1.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>As you can see from the previous slides, language is incredibly complex. Words can have multiple meanings. All of these make text data messy and hard for machines to interpret. So, how do we deal with this complexity? That’s where Text Analytics or Natural Language Processing (NLP) come in. These techniques give us tools to extract structure and meaning from unstructured text, helping us turn language into something computers can analyze and learn from.</p>
<p>When we talk about Text Analytics, we’re referring to a set of techniques – linguistic, analytical, and predictive — that allow us to extract structure and meaning from unstructured text data. You’ll often hear the term Natural Language Processing, or NLP, in academic contexts. Essentially, NLP is the scholarly term for what industry often calls Text Analytics. It’s similar to the distinction between “search” in everyday language and “information retrieval” in research.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="role-of-natural-language-processing-in-information-retrieval" class="title-slide slide level1 center">
<h1>Role of Natural Language Processing in Information Retrieval</h1>

</section>

<section>
<section id="natural-language-searching" class="title-slide slide level1 center">
<h1>Natural Language Searching</h1>
<aside class="notes">
<p>In recent years, there has been an unprecedented growth in unstructured text data across digital environments. Scholarly publications, institutional reports, social media content, and various forms of grey literature now constitute an immense corpus of textual information that is not easily represented within structured databases. This proliferation of unstructured text has created a pressing need for search systems that can effectively interpret and retrieve relevant information from natural language sources.</p>
<p>Historically, information retrieval systems have relied on Boolean search models, which require users to construct queries using logical operators such as AND, OR, and NOT. While Boolean searching offers precision and control, it also imposes a steep learning curve and often results in inefficiencies for non-expert users. In contrast, contemporary search interfaces increasingly emphasize natural language querying, allowing users to articulate information needs in the same way they would express them conversationally — for example, by typing or speaking full questions rather than isolated keywords.</p>
<p>This preference for natural queries reflects a broader transformation in user expectations, influenced by advances in natural language processing (NLP) and the ubiquity of intelligent search assistants. Users now anticipate that systems will interpret intent, context, and semantics, rather than rely solely on keyword matching.</p>
<p>The shift toward natural language searching represents a critical evolution in information retrieval, one that bridges the gap between human linguistic expression and computational understanding.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="natural-langauge-indexing" class="slide level2">
<h2>Natural Langauge Indexing</h2>
<ul>
<li><p>Based on existing vocabulary of documents</p></li>
<li><p>Terms are extracted or derived from titles, abstracts, full text</p></li>
<li><p>Terms are in title, abstract, descriptor, full-text fields</p></li>
<li><p>Searcher inputs any term likely to occur in free text</p></li>
</ul>
<aside class="notes">
<p>Natural Language Indexing is the form of indexing language which is used to represent subjects of object in a database. It does not use a controlled vocabulary as the source for indexing terms. Instead it is based on the existing vocabulary of the object being represented. Terms are extracted from the body of the object text or derived from titles or abstracts of the object.</p>
<p>Any term or concept that is present in the object may be deemed important and therefore can be represented in the record describing the object.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol type="1">
<li>Word Prediction
<ul>
<li>Assistive technologies (TextHelp)</li>
<li>Google, Bing, Yahoo query suggestions</li>
</ul></li>
</ol>

<img data-src="images/7.png" class="quarto-figure quarto-figure-center r-stretch" width="402"><aside class="notes">
<p>NLP plays a central role in enhancing how users interact with search systems, particularly by improving query formulation, interpretation, and completion. One prominent area of application is word prediction, which assists users in constructing queries more efficiently and accurately. By analyzing large corpora of search behavior and linguistic patterns, NLP models can anticipate what a user is likely to type next, reducing effort and improving precision in information retrieval.</p>
<p>This functionality is integral to assistive technologies, such as TextHelp and similar tools, which support individuals with language, literacy, or motor challenges. Through predictive text and contextual suggestions, these systems enable smoother communication and more accessible search experiences. In the context of libraries and digital repositories, such tools can be particularly valuable for users with diverse accessibility needs, helping to ensure equitable participation in digital information environments.</p>
<p>In mainstream search engines such as Google, Bing, and Yahoo, NLP powers query suggestion and auto-completion features that guide users toward refined or alternative queries. For example, as a user begins typing “library digital,” the system may suggest completions such as “library digital archives” or “library digital collections,” reflecting both linguistic context and aggregated search trends. These predictive systems rely on sophisticated language models that analyze syntax, semantics, and user intent at scale.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-1" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="2" type="1">
<li>Spelling Correction
<ul>
<li><p>Autocorrect <img data-src="images/3.1.png"></p></li>
<li><p>Did you Mean <img data-src="images/4.png"></p></li>
</ul></li>
</ol>
<aside class="notes">
<p>Another key application of NLP in search systems is <strong>spelling correction</strong>, which directly improves the accuracy and usability of information retrieval. Users frequently make typographical errors, omit letters, or misremember proper names, and without automated correction, such errors would significantly degrade retrieval performance.</p>
<p>The first and most familiar implementation of this is <strong>autocorrect</strong>. Autocorrect mechanisms use NLP models trained on extensive language corpora and user query logs to identify likely misspellings and replace them with the intended terms in real time. For instance, when a user types “envrionmental policy,” the system automatically recognizes the anomaly and corrects it to “environmental policy.” These systems typically rely on probabilistic models, such as edit distance algorithms, phonetic similarity measures, and contextual embeddings, to determine the most plausible correction.</p>
<p>A related and widely recognized feature is the <strong>“Did you mean”</strong> suggestion, popularized by search engines such as Google and Bing. Instead of automatically replacing the query, the system proposes an alternative based on linguistic probability and query frequency. This approach maintains user agency by offering correction as a suggestion rather than enforcing substitution.</p>
<p>Both autocorrect and “Did you mean” functionalities exemplify how NLP enhances the robustness and inclusivity of search systems. They mitigate the effects of human error, non-native language use, and spelling variation, thereby improving retrieval quality and user satisfaction.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-2" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="3" type="1">
<li><p>Text Categorization</p>
<ul>
<li>News agencies: classifying incoming news stories</li>
<li>Search engines: classifying queries</li>
<li>Identifying spam emails</li>
<li>Routing email or documents to appropriate people</li>
</ul></li>
<li><p>Terminology Extraction</p>
<ul>
<li>Differentiate between useful index terms and ‘noise’</li>
<li>Help lexicographers identify new terminology</li>
<li>Term extraction systems process scientific papers to identify terminology, possibly comparing it with a known list</li>
</ul></li>
<li><p>Speech Recognition</p>
<ul>
<li>Spoken Dialogue System</li>
<li>iPhone Voice Search</li>
</ul></li>
</ol>
<aside class="notes">
<p>Beyond word prediction and spelling correction, NLP supports several additional applications that are foundational to modern information retrieval and search system design. These include <strong>text categorization, terminology extraction, and speech recognition</strong> – each addressing a distinct aspect of how systems interpret, organize, and interact with human language.</p>
<p>Text categorization refers to the automatic classification of documents or queries into predefined categories based on their content. In news agencies, for example, NLP-driven classifiers are used to automatically sort incoming stories into topical domains such as politics, economics, or sports, enabling faster editorial workflows and real-time content organization. Similarly, search engines employ query classification to interpret the intent behind a user’s input—distinguishing, for instance, whether a query is informational (“What is climate change?”), navigational (“UN Climate Report 2024”), or transactional (“buy solar panels”). Accurate classification supports more relevant ranking and personalized retrieval. In communication systems, text categorization is applied to spam detection, filtering unwanted or malicious emails by recognizing linguistic and structural patterns associated with spam content. It is also used for document routing, where NLP systems automatically direct incoming emails or reports to the appropriate department or individual, streamlining information flow within organizations.</p>
<p>Another important application is terminology extraction, which focuses on identifying and isolating domain-specific terms within large text corpora. In information retrieval, this process helps differentiate between useful index terms—those that carry semantic weight—and background “noise” such as common or generic words. For lexicographers and subject specialists, terminology extraction supports the identification of emerging concepts and new vocabulary. For instance, in scientific publishing, NLP-driven term extraction systems can analyze research articles to identify newly introduced technical terms and compare them against established term lists or ontologies. This capability is particularly valuable in building and updating controlled vocabularies, thesauri, and ontologies that underpin advanced search systems, ensuring that indexing and retrieval remain aligned with evolving disciplinary language.</p>
<p>Finally, speech recognition represents a critical bridge between spoken language and searchable text. Modern spoken dialogue systems and voice-activated assistants rely on NLP to transcribe and interpret speech, enabling users to conduct searches or issue commands using natural spoken queries. A familiar example is iPhone Voice Search (Siri), which allows users to speak queries such as “Find articles on information retrieval models” or “Where is the nearest library?” The system processes the audio input, converts it into text, applies NLP-based intent detection, and retrieves relevant results. Speech recognition not only enhances user convenience but also expands accessibility—benefiting individuals with mobility impairments, visual disabilities, or those operating in hands-free environments.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-3" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="6" type="1">
<li><p>Named Entity Recognition</p>
<ul>
<li>Identification of key concepts (eg. people, places, organizations)</li>
<li>Increase precision of IR (New companies in New York vs. Companies in New York)</li>
<li>Support navigation</li>
<li>Improve machine translation</li>
<li>Speech synthesis, auto-summarization, etc.</li>
</ul></li>
</ol>

<img data-src="images/10.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Named Entity Recognition, or NER, is one of the most important applications of NLP in searching. It identifies key concepts in text—things like people, places, organizations, dates, and more. It helps improve the precision of information retrieval.For example, consider the query ‘New companies in New York’. Without NER, the system might return results about any companies in New York, old or new. With NER, the system understands that ‘New’ refers to the adjective describing companies, not part of the location, and retrieves more accurate results.</p>
<p>NER also supports navigation by allowing systems to organize and filter results based on entities. Beyond search, it plays a role in machine translation, speech synthesis, and even auto-summarization because understanding entities is key to understanding meaning. NER helps search systems move beyond simple keyword matching to understanding the actual concepts users care about.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-4" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="7" type="1">
<li>Information Extraction
<ul>
<li>Identification of entities + relationships</li>
<li>Based on pre-defined structures</li>
<li>Can be used for metadata retrieval or store in database and query against it</li>
</ul></li>
</ol>

<img data-src="images/13.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Information Extraction goes a step beyond Named Entity Recognition. While NER identifies entities like people, places, and organizations, Information extraction looks at the relationships between those entities. For example, not just recognizing ‘John Smith’ and ‘Harvard University,’ but also understanding that John Smith is affiliated with Harvard.</p>
<p>Information Extraction typically works based on pre-defined structures or templates. These structures help the system know what kinds of relationships to look for, such as ‘author of,’ ‘located in,’ or ‘works at.’ This structured approach makes Information Extraction very useful for organizing data.</p>
<p>In the context of search, Information Extraction can be used to generate metadata automatically. For instance, extracting author names, publication dates, and affiliations from research papers and storing them in a database. Once this metadata is structured, we can query against it efficiently, improving both precision and recall.</p>
<p>Beyond search, Information Extraction supports advanced applications like building knowledge graphs, improving recommendation systems, and enabling semantic navigation in digital libraries.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="free-text-searching" class="slide level2">
<h2>Free Text Searching</h2>

<img data-src="images/15.png" class="quarto-figure quarto-figure-center r-stretch" width="565"><div class="footer">
<p>Source: Markey Ch-7</p>
</div>
<aside class="notes">
<p>Free text searching refers to a retrieval approach in which users enter search terms directly, without relying on a predefined indexing structure or controlled vocabulary. In this model, the search engine scans the text of documents—such as titles, abstracts, and full content—for matches to the words or phrases supplied by the user. This method leverages the actual language used within the corpus, allowing for flexible and dynamic searching.</p>
<p>In contrast, a controlled vocabulary system, such as the Library of Congress Subject Headings or MeSH (Medical Subject Headings), employs a standardized set of terms that describe concepts consistently across documents. Controlled vocabularies promote precision and interoperability by ensuring that related materials are indexed under the same authorized terms. However, they also require users to understand the specific terminology of the indexing schema, which can be restrictive or unintuitive for those unfamiliar with it.</p>
<p>Free text searching, by comparison, enables users to express their queries in their own words. For example, a user interested in research on renewable energy might use a keyword query such as “solar energy policy”. A natural language query, on the other hand, might take the form of “How are governments supporting the adoption of solar energy?”</p>
<p>While both approaches rely on textual input, natural language queries introduce linguistic variation, context, and intent, which can be better interpreted through natural language processing techniques. Controlled vocabularies offer precision and consistency, whereas free text searching offers accessibility and expressiveness.</p>
<p>Understanding this distinction provides the foundation for exploring how modern search systems combine these methods to achieve both semantic depth and user-centered flexibility in information retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="free-text-searching-in-databases" class="slide level2">
<h2>Free Text Searching in Databases</h2>
<ul>
<li>Terms added at the discretion of the cataloger</li>
<li>Do not come from a controlled vocabulary or from the words of the document</li>
<li>Cataloger tries to match user’s terms (user warrant)</li>
<li>Not a frequent practice</li>
<li>Can be used in combination with controlled vocabulary or natural language indexing</li>
</ul>
<aside class="notes">
<p>If a cataloger is providing free text terms, the terms are not coming from either a controlled vocabulary or from the object’s text. The cataloger decides to add terms that they believe match the user’s own search terms or that are closer to the everyday use of the term.</p>
<p>This is not a frequent practice in cataloging but if a term is very new to a language, it may not be represented in a controlled vocabulary yet, or the controlled vocabulary may use an alternate term than the one used by users or within the literature of the discipline. The cataloger would then decide to use a more commonly used term instead of one from the controlled vocabulary or the object.</p>
<p>Free text can also be used in combination with controlled vocabulary and/or natural language indexing.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="user-defined-tagging" class="slide level2 smaller">
<h2>User-Defined Tagging</h2>
<ul>
<li>Has many labels such as <code>user-supplied, folksonomy, tagging, social classification</code></li>
<li>It is really not a new practice but one that has recently become the buzz on the Web with the emergence of blogs and media sharing sites like Blogger, Flickr, YouTube, etc.
<ul>
<li>researchers in image retrieval have explored this idea</li>
<li>researchers in organization of information, thesauri development, indexing, subject representation have also explored this idea</li>
</ul></li>
<li>To date is being used to tag images, web pages, blogs, library catalogs, etc.</li>
</ul>
<aside class="notes">
<p>Currently we have seen a large amount of professional and research literature discussing an emerging form of indexing language, User-defined or User-Supplied terms. While I say it is emerging, this concept is really not a new idea to library and information science (LIS). Many LIS researchers have been conducting research into this area since the 1990s. It has recently more popular on the Web with the emergence of blogs and media sharing sites like Blogger, Flickr, YouTube, etc.</p>
<p>This concept has many labels (user-supplied, folksonomy, tagging, social classification). It has yet to be decided which term will prevail.</p>
<p>Researchers in image retrieval have explored this idea since the 1990s, and even earlier in specific image-related contexts, such as journalism or newspaper archives. Researchers in organization of information, thesauri development, indexing, subject representation have also explored this idea as a source of more user-centered subject terms or to learn more about how users naturally organize and describe subjects of objects.</p>
<p>To date it is being used to “tag” images, web pages, blogs, library catalogs, etc.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="coversational-search" class="slide level2">
<h2>Coversational Search</h2>
<ul>
<li>Voice-based queries</li>
<li>Chatbots in Libraries</li>
</ul>

<img data-src="images/14.png" class="quarto-figure quarto-figure-center r-stretch" width="401"><aside class="notes">
<p>Conversational search represents an important evolution in information retrieval, moving beyond traditional keyword or Boolean querying toward interactive, dialogue-based engagement bfetween users and search systems. This mode of search is often characterized by the use of voice-based queries, where users articulate information needs verbally rather than through typed input.</p>
<p>Prominent examples include Google Assistant and Amazon Alexa, which employ advanced natural language understanding to interpret queries such as “What are the latest articles on renewable energy policy?” or “Find me books on digital archiving.” Increasingly, similar conversational interfaces are being explored within library and digital repository systems, enabling users to locate materials, check availability, or receive research guidance through spoken or text-based interaction.</p>
<p>The benefits of conversational search are especially significant in terms of accessibility and inclusivity. Voice and natural language interfaces lower barriers for users who may have limited technical expertise, motor impairments, or visual disabilities. They also align with evolving expectations shaped by ubiquitous consumer technologies—where interacting with systems through natural language feels intuitive and human-like.</p>
<p>From an information science perspective, conversational search highlights the convergence of speech recognition, natural language processing, and contextual understanding, marking a shift from static query-response models to dynamic, user-centered dialogue systems.</p>
<p>Building upon the concept of conversational search, chatbots have emerged as practical implementations of natural language processing within the library context. These systems function as virtual reference services, designed to assist users in navigating library resources, answering common questions, and providing real-time guidance without direct human intervention.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="applications-in-lis" class="slide level2">
<h2>Applications in LIS</h2>
<ul>
<li>Digital libraries and institutional repositories</li>
<li>Discovery systems and OPACs</li>
<li>Personalized recommendations</li>
</ul>
<aside class="notes">
<p>The principles of natural language search have numerous and growing applications within Library and Information Science field, fundamentally transforming how users interact with information systems.</p>
<p>First, within digital libraries and institutional repositories, natural language search enables more intuitive exploration of scholarly content. Instead of requiring users to navigate complex metadata schemas or controlled vocabularies, systems can now interpret queries expressed in everyday language—facilitating discovery across articles, theses, datasets, and multimedia resources. For librarians, this enhances accessibility and aligns with open access and knowledge dissemination goals.</p>
<p>Second, discovery systems and OPACs increasingly incorporate natural language interfaces. Modern discovery layers, such as Primo, Summon, and EBSCO Discovery Service, are integrating NLP-driven ranking and query expansion capabilities. These allow users to formulate broad or conversational queries and still retrieve relevant materials without exact keyword matching. This evolution transforms the OPAC from a static catalog into a dynamic, user-centered search environment.</p>
<p>Finally, natural language understanding also supports personalized recommendation systems within LIS platforms. By analyzing user queries, search behavior, and reading patterns, these systems can suggest related materials or anticipate research needs. Such personalization extends beyond convenience, it supports scholarly serendipity, enhances learning outcomes, and fosters engagement with institutional collections.</p>
<p>Therefore, the application of natural language search in LIS reflects a shift from system-driven retrieval toward user-centered discovery, integrating linguistic intelligence into the core functions of information organization and access.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="future-directions" class="slide level2">
<h2>Future Directions</h2>
<ul>
<li>Multimodal Searching</li>
<li>Intelligent Research Assistants</li>
<li>Knowledge Graphs Integration</li>
<li>Multilingual and Cross-Lingual Search</li>
<li>More!!</li>
</ul>
<aside class="notes">
<p>Looking ahead, there are several emerging directions shaping the future of natural language search in scholarly and library contexts.</p>
<p>One key area is multimodal search, which integrates text, image, and voice inputs within a unified retrieval framework. This approach enables users to express information needs through multiple channels—for example, submitting an image of a manuscript page, describing it verbally, or typing a related phrase. Such multimodal systems hold promise for archives, museums, and digital humanities projects where non-textual artifacts are central.</p>
<p>A second direction involves the development of intelligent research assistants for scholarly environments. Building upon chatbot and dialogue technologies, these systems aim to support complex, iterative research interactions. Rather than retrieving a single result set, conversational AIs could guide users through literature review processes, suggest relevant methodologies, or identify citation networks – all within a sustained, context-aware dialogue. This represents a paradigm shift from search as a one-time transaction to search as an ongoing, collaborative process.</p>
<p>Finally, the integration of knowledge graphs offers a powerful means of connecting disparate data sources and enhancing semantic understanding. By representing entities—such as authors, institutions, topics, and publications—and their relationships, knowledge graphs allow search systems to infer deeper connections and provide richer, more explainable results. When combined with neural retrieval models, these structures enable contextualized, reasoning-based discovery across large scholarly ecosystems.</p>
<p>Collectively, these directions signal a future in which search systems evolve from passive retrieval tools into intelligent research partners, capable of understanding, reasoning, and assisting within complex academic and informational contexts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="text-mining" class="slide level2 smaller">
<h2>Text Mining</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><code>Text mining is a process of automatically extracting information from the text with the aim of generating new knowledge</code></p>
<ul>
<li><p>It is a specialized interdisciplinary field combining techniques from linguistics, computer science, and statistics to build tools that can efficiently retrieve and extract information from digital text</p></li>
<li><p>It assists in the automatic classification of documents</p></li>
<li><p>In text mining, “words are attributes or predictors and documents are cases or records, together these form a sample of data that can feed in well-known learning methods” (Weiss et al., 2005)</p></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/20.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Weiss et al.&nbsp;(2005). Overview of text mining. In: Weiss et al.&nbsp;(eds) Text mining:Predictive methods for analyzing unstructured information. Springer, New York, NY, pp 1–13</p>
</div>
<aside class="notes">
<p>With the foundation of IR and NLP in place, let’s explore what text mining is really about.</p>
<p>Text mining as both a <code>concept</code> and a <code>process</code>. At a high level, text mining refers to the automatic extraction of information from text with the goal of generating new knowledge – not just retrieving documents, but uncovering patterns, relationships, and insights that are not immediately visible through manual reading.</p>
<p>The figure on this slide shows that text mining is not a single step, but a pipeline. Also, notice that the arrows in the figure flow back to the database which emphasizes that text mining is a iterative process, and not linear.</p>
<p>We begin with text sources, which can include articles, social media posts, reports, logs, or any form of unstructured or semi-structured text. These texts are then <code>transformed into a corpus</code> format, where decisions are made about what counts as a document, how text is segmented, and what metadata is retained—already a point where human judgment and data stewardship matter.</p>
<p>Next comes <code>text pre-processing</code>, where raw text is cleaned and normalized. This often includes tokenization, stopword removal, normalization, and sometimes stemming or lemmatization. These steps are essential because computational models cannot work directly with raw language—they require structured representations.</p>
<p><code>Exploratory Text Analysis</code> (ETA) follows, allowing us to understand the data before modeling. This step helps identify dominant terms, distributions, anomalies, or biases in the corpus, and often informs whether earlier preprocessing steps need to be revisited.</p>
<p>The <code>NLP annotation</code> stage adds linguistic structure to text, such as part-of-speech tags, named entities, syntactic dependencies, or semantic labels. These annotations enrich the data and enable more advanced analysis.</p>
<p>Once text is represented numerically and linguistically, we can apply models—including classification, clustering, topic modeling, or prediction. As Weiss et al.&nbsp;(2005) note, in text mining, words function as attributes or predictors, documents function as cases, and together they form structured data that can be used by standard machine learning methods.</p>
<p>Finally, visualization helps us interpret results, communicate findings, and validate assumptions. Importantly, outputs at every stage are stored back into the database, reinforcing that text mining relies on strong data management and documentation practices.</p>
<p>We will cover all the text mining process just mentioned in much more depth in the coming weeks with hands-on lab assignments.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="brief-history-of-text-mining" class="slide level2 smaller">
<h2>Brief History of Text Mining</h2>

<img data-src="images/clipboard-1579569194.png" class="quarto-figure quarto-figure-center r-stretch" width="400"><div class="footer">
<p><a href="https://doi.org/10.1007/978-3-030-85085-2_1">Lamba and Madhusudhan. (2022). Ch-1 The Computational Library</a></p>
</div>
<aside class="notes">
<p><em><code>{Zoom-in to see the figure or Right-click to save it!}</code></em></p>
<p>Text mining today is based on techniques that were introduced in the 1960s and while the abilities of systems and the algorithms used have been refined, the process remains the same.</p>
<p>The text mining phenomenon first began for ext document cataloging, followed by text summarization to generate abstracts. The earliest instance of text classification and summarization in libraries was the development of the first library catalog in 1674 by Thomas Hyde for the Bodleian Library, University of Oxford, and the first index card in 1876 by Melvil Dewey.</p>
<p>It was followed by the summarization of a large body of texts in 1898 (from the collaboration between the Physical Society of London and the Institution of Electrical Engineers) and the generation of document abstracts by a computer at IBM in 1958 by Luhn.</p>
<p>In 1948, Shannon developed a new area of information theory, which is among the most notable developments of the twentieth century. Information flow in the form of the Internet, modern data compression protocols, manipulating applications, document storage, various indexing systems, and search systems are some of the applications of the information theory.</p>
<p>In 1950, the science of bibliometrics came into existence. It gives a numerical measure to analyze texts. It is an application of text processing that results in a collection of essential articles that can track the development path of a given discipline and is analogous to the word frequency calculation in text mining. In 1961, Doyle extended on Luhn’s work. He suggested a new method to classify library information into word frequencies and associations, which is now the highly automated and systematic method for browsing information in libraries.</p>
<p>In the 1960s, NLP was developed from information science and linguistics to comprehend how natural languages are learned and modeled. The initial efforts of using NLP to translate a language on a computer failed, and soon in 1995, the focus was changed to processing answers to questions.</p>
<p>The computers’ availability in the 1960s gave rise to NLP applications on computers known as computational linguistics. Luhn’s abstract generation method is an example of NLP. Clustering is an NLP task that groups documents together based on their similarity or distance measure when no previous information is available.</p>
<p>In 1992, Cutting et al.&nbsp;provided an early clustering analysis of browsing a document collection when a query could not be created. Subsequently, in 2002, Tombros et al.&nbsp;used query-based clustering to perform hierarchical clustering of a document corpus.</p>
<p>The next phase of NLP was related to understanding the context and meaning of the information instead of emphasizing the words used in the documents. Such developments were observed in the field of bibliometrics, where the context of documents was considered.</p>
<p>Modern text mining followed a similar path and arose from the above developments in NLP through the 1990s. In the 2000s, NLP practitioners can either use the domain-independent stemming and parsing strategies to build features or use the newer text categorization to tag documents.</p>
<p>Thus, the early text mining tasks in information science, library science, and NLP were primarily related to different forms of information summarization and information retrieval, such as abstracts, indexes, and grouping of documents, but the later text mining tasks were focused on information extraction. The relationship and content information are extracted by tagging each document of the corpus. Modern text mining can be partly defined based on the information extraction methods that support information discovery of latent patterns in the text bodies.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="different-text-mining-tasks" class="slide level2">
<h2>Different Text Mining Tasks</h2>

<img data-src="images/21.png" class="r-stretch"><aside class="notes">
<p>This slide gives you a high-level overview of some of the most common text mining tasks.</p>
<p>On the left, we have document classification, also called text categorization. Here, a new document is passed through a series of classifiers and based on those decisions, the document gets assigned to one or more categories.</p>
<p>In the middle, we have information retrieval. This is what’s happening when you search a database or Google. You start with an input document or query, and the system finds the most relevant documents from a larger collection.</p>
<p>On the right, we have clustering. Unlike classification, clustering doesn’t use predefined labels. Instead, the system automatically groups documents based on similarity, so you might end up with Group 1, Group 2, and Group 3 without naming them in advance.</p>
<p>And at the bottom, we have information extraction. This is about pulling structured information out of unstructured text—for example, identifying “25 million dollars” as revenue and “45 thousand dollars” as profit and placing them into a spreadsheet.</p>
<p>So, all of these common text mining tasks solve different problems such as assigning labels, finding relevant documents, grouping similar texts, or extracting specific facts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="advanced-text-mining-approaches" class="slide level2">
<h2>Advanced Text Mining Approaches</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/22.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
<aside class="notes">
<p>This slide gives you a big-picture overview of the advanced text mining and AI techniques we will be covering throughout the course. You will see approaches like topic modeling, sentiment analysis, network text analysis, predictive modeling or machine learning, deep neural networks, and large language models, along with how results can be communicated through dashboards and visualizations.</p>
<p>At this stage, you do not need to understand how each of these methods works technically. The goal here is simply to show you the landscape of approaches that are possible when working with text data.</p>
<p>We will return to each of these methods in the upcoming modules and cover them in depth—step by step—focusing on what they do, how they work, and how they can be applied responsibly to real-world problems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="images/ou.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="index_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="index_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="index_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="index_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"theme":"whiteboard"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: "separate-page",

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>